---
title: 'The \mathbb{R}-algebra of quasiknowledge and convex optimization'
date: 2022-08-09
permalink: /posts/2022/08/convex-knowledge/
tags:
  - cs.ml
  - cs.cc
  - quant-ph
---
<head>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<p>(older version <a
href="https://github.com/qudent/qudent.github.io/blob/935968fec7d4e89e7953f460d1c2b1093bf0da6b/_posts/2022-07-25-convex-knowledge.md">here</a>.
The old version is more verbose/philosophical, in this one, I try to
avoid burying the lede and put the definitions first.)</p>
<h2 id="abstract">1. Abstract</h2>
<p>I develop a convex description of a classical or quantum learner’s or
agent’s state of knowledge about its evironment in a bid to apply
methods from convex optimization and duality to optimal learning/control
problems.</p>
<h3 id="intuition-and-motivation">1.1 Intuition and motivation</h3>
<p>In the foundations of quantum physics, <a
href="https://en.wikipedia.org/w/index.php?title=Generalized_probabilistic_theory&amp;oldid=1095657221">generalized
probabilistic theories</a> are a family of mathematical structures that
generalize both quantum physics and classical probability theory, and -
to a limited degree - allow reasoning about quantum and classical
systems using the same algebraic manipulations. The aim of this note is
to develop a similarly general structure to describe the notion of
<em>an agent’s knowledge about its environment</em>.</p>
<p>In probability theories, one could describe that by a joint
probability distribution over the environment’s and the agent’s internal
memory states. The approach I present is different in <strong>two basic
ways:</strong></p>
<ol type="1">
<li><p><strong>Equivalent joint probability distributions are the same
state of knowledge:</strong> In terms of “how much the agent knows about
its environment”, many joint probability distributions should be
considered equivalent - for example, if the environment and the internal
memory are both described by one bit, the joint probability matrices<a
href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a> <span
class="math inline">\(\begin{pmatrix}0.5 &amp; 0\\0 &amp;
0.5\end{pmatrix}\)</span> and <span
class="math inline">\(\begin{pmatrix}0 &amp; 0.5\\0.5 &amp;
0\end{pmatrix}\)</span> both correspond to the agent having complete
knowledge of the environment. We will formalize this idea by an
equivalence relation over which we take equivalence classes. Then only
distinct equivalence classes correspond to distinct “states of
knowledge”.</p></li>
<li><p><strong>The addition used for convex mixtures is a direct, not
entrywise sum:</strong> A basic feature of classical probability
distributions and mixed quantum states is <em>convexity</em>: If <span
class="math inline">\(A\)</span> and <span
class="math inline">\(B\)</span> are valid probability distributions,
transition matrices or similar, and <span class="math inline">\(0\leq p
\leq 1\)</span>, an object denoted by <span
class="math inline">\(c_p(A,B):=pA+(1-p)B\)</span> exists and is to be
interpreted as “the result of choosing <span
class="math inline">\(A\)</span> with probability <span
class="math inline">\(p\)</span> and <span
class="math inline">\(B\)</span> with probability <span
class="math inline">\(1-p\)</span>”. In probability theory, <span
class="math inline">\(A\)</span> and <span
class="math inline">\(B\)</span> are some vectors or matrices, <span
class="math inline">\(pA\)</span> denotes the <strong>entrywise</strong>
product with <span class="math inline">\(p\)</span>, and the <span
class="math inline">\(+\)</span> sign denotes the <strong>entrywise
sum</strong> of these objects.</p>
<p>In our notion of “states of knowledge”, a “convex mixture” <span
class="math inline">\(c_p(A,B)=pA+(1-p)B\)</span> should be interpreted
as “the system is in state of knowledge <span
class="math inline">\(A\)</span> with probability <span
class="math inline">\(p\)</span>, and in state of knowledge <span
class="math inline">\(B\)</span> with probability <span
class="math inline">\(1-p\)</span>.” This wouldn’t work if we just took
elementwise convex combinations of the joint probability distributions:
Reusing the example from 1., <span class="math inline">\(\frac{1}{2}
\begin{pmatrix}0.5 &amp; 0\\0 &amp;
0.5\end{pmatrix}+\frac{1}{2}\begin{pmatrix}0 &amp; 0.5\\0.5 &amp;
0\end{pmatrix}=\begin{pmatrix}0.25 &amp; 0.25\\0.25 &amp;
0.25\end{pmatrix}\)</span> corresponds to a state of complete ignorance
even though the constituent matrices correspond to perfect knowledge. We
need the system to remember <em>which</em> constituent matrix was
chosen, and can do that with <em>direct sums:</em> Interpreting <span
class="math inline">\(\oplus\)</span> as a direct sum of the columns,
<span class="math inline">\(\frac{1}{2} \begin{pmatrix}0.5 &amp; 0\\0
&amp; 0.5\end{pmatrix} \oplus \frac{1}{2}\begin{pmatrix}0 &amp; 0.5\\0.5
&amp; 0\end{pmatrix}= \begin{pmatrix} 0.25 &amp; 0 &amp; 0 &amp; 0.25\\
0 &amp; 0.25 &amp; 0.25 &amp; 0 \end{pmatrix}.\)</span> We interpret the
memory space of the right-hand side matrix as containing an additional
bit that stores whether the knowledge is encoded as in the left or as in
the right summand. It will turn out that the right-hand side matrix is
the state of complete knowledge as well (another representative of the
same equivalence class that contains <span
class="math inline">\(\begin{pmatrix}0.5 &amp; 0\\0 &amp;
0.5\end{pmatrix}\)</span> and <span
class="math inline">\(\begin{pmatrix}0 &amp; 0.5\\0.5 &amp;
0\end{pmatrix}\)</span>), just like we want: Having complete knowledge
in either of two ways is just equivalent to having complete knowledge
all the time.</p>
<p>So in our formal algebraic structure of “states of knowledge”
describing classical physics, multiplication with a nonnegative scalar
is defined elementwise, and addition is implemented by a direct sum. If
we find a way to subtract states of knowledge as well (or multiply with
a negative scalar), we have all the ingredients needed for a real vector
space (if everything fulfills the axioms). We will effectively do this
by a <em>Grothendieck group construction</em>, which is a consistent way
to add enough negatives to an algebraic structure so that everything has
an inverse (just like negative numbers were invented as “numbers that
don’t actually exist, but are useful for calculations” starting with
natural numbers). In the end, the physical states of knowledge are a
convex subset of a vector space.</p></li>
</ol>
<p>I see two applications:</p>
<ol type="1">
<li>We will be able to describe the problem of finding an optimal
strategy to manipulate or learn about the environment as a convex
optimization problem - and hopefully use duality to find lower bounds
for the agent’s ability to do so as well. We can describe and generalize
results from quantum complexity theory, in particular <a
href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.113.1101&amp;rep=rep1&amp;type=pdf">this
paper by Barnum-Saks-Szegedy</a> and the related <a
href="https://arxiv.org/abs/1504.06943">quantum adversary
bound-universal query algorithm duality</a>, in our formalism - and
immediately generalize the convex optimization problems therein to
classical or decoherent-quantum situations.</li>
<li>Leaving mathematical rigour a bit (as we haven’t defined infinite
dimensional vector spaces), we can also solve formal differential
equations and construct power series that describe e.g. the evolution of
a learner’s knowledge over time when it observes a Poisson process
generating experimental data. This will involve a notion of
multiplication of “states of knowledge” as well, corresponding to an
agent having access to two states of knowledge in parallel. So in fact,
we are dealing with something called an <span
class="math inline">\(\mathbb{R}\)</span>-algebra (which we can always
interpret as a vector space as well).</li>
</ol>
<p>In fact (I didn’t write this down yet, and it’s not supposed to be
clear from this introduction, and), in the case of pure quantum states,
the resulting structure should be equivalent to that of the positive
semidefinite matrices on the environment, as a subset of the Hermitian
matrices, with elementwise addition and multiplication.</p>
<h3 id="outline">1.2. Outline</h3>
<p>In sections 2-5, I develop the concrete situations of classical, pure
quantum, and mixed quantum physics and obtain structures <span
class="math inline">\(\mathcal{S}^\pm_{\mathrm{class}},\)</span> <span
class="math inline">\(\mathcal{S}^\pm_{\mathrm{quant}},\)</span> <span
class="math inline">\(\mathcal{S}^\pm_{\mathrm{decoh}}.\)</span> More
precisely, section 2 defines sets, sections 3-4 structure on that sets,
and section 5 an equivalence relation that makes equivalent “states of
quasiknowledge” equal. Then section 5 mentions the algebraic axioms that
these structures fulfill. The remaining sections discuss applications,
in particular, section 6 is supposed to be a simple, concrete
example.</p>
<p><strong>Remark:</strong> If you want to speed up reading or don’t
know quantum physics, you can skip all mentions of non-classical
situations. The example in section 6 may also be helpful.</p>
<h2 id="sets-before-modding-out-the-equivalence-relation">2. Sets before
modding out the equivalence relation</h2>
<p>Consider an agent within an environment that could be in a state
<span class="math inline">\(e\in E,\)</span> with some internal memory
state <span class="math inline">\(m\in M.\)</span></p>
<ol type="1">
<li>In the classical case, we describe the situation by a probability
matrix <span class="math inline">\((p_{e,m})_{(e,m)\in E\times
M}\in(\mathbb{R}^+)^{E\times M},\)</span> where <span
class="math inline">\(\mathbb{R}^+\)</span> denotes the set of
<strong>nonnegative</strong> real numbers,</li>
<li>in the quantum case without decoherence, we have a bipartite quantum
state <span class="math inline">\((\psi_{e,m})_{(e,m)\in E\times
M}\in\mathbb{C}^{E\times M},\)</span> and</li>
<li>we model the quantum case with decoherence by adding an additional
subsystem <span class="math inline">\(D\)</span> into which the state is
supposed to have decohered, and and consider a pure quantum state <span
class="math inline">\((\psi_{d,e,m})_{(d,e,m)\in D\times E\times
M}\in\mathbb{C}^{D\times E\times M}\)</span> again.<a href="#fn2"
class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a></li>
</ol>
<p>For a fixed <span class="math inline">\(E,\)</span> we denote and
define sets of possible situations (which will turn into our desired
notions of “states of knowledge” after modding out equivalence relation
in section 5):</p>
<ol type="1">
<li><span
class="math inline">\(\mathcal{S}&#39;^E_{\mathrm{class}}:=\left\{(M,P)\mid
|M|&lt;\infty, P\in(\mathbb{R}^+)^{E\times M}\right\},\)</span></li>
<li><span
class="math inline">\(\mathcal{S}&#39;^E_{\mathrm{quant}}:=\left\{(M,\Psi)\mid
|M|&lt;\infty, \Psi\in\mathbb{C}^{E\times M}\right\},\)</span></li>
<li><span
class="math inline">\(\mathcal{S}&#39;^E_{\mathrm{decoh}}:=\left\{(D,M,\Psi)\mid
|D|&lt;\infty, |M|&lt;\infty, \Psi\in\mathbb{C}^{D\times E\times
M}\right\}.\)</span></li>
</ol>
<p>In other words, we do not fix <span class="math inline">\(M\)</span>
and <span class="math inline">\(D\)</span> (or limit their sizes beyond
requiring they are finite), but consider them part of the description.
Furthermore, we don’t force the classical probability distributions or
quantum states to be normalized. We leave out the superscript <span
class="math inline">\(E\)</span> and/or the subscript <span
class="math inline">\(\mathrm{class},\)</span> <span
class="math inline">\(\mathrm{quant},\)</span> <span
class="math inline">\(\mathrm{decoh}\)</span> if they are
irrelevant.</p>
<p>We define <span
class="math inline">\(\mathcal{S}&#39;^\pm:=\mathcal{S}&#39;\times\mathcal{S}&#39;\)</span>
(for classical, coherent-quantum, or decohering-quantum states). Denote
a tuple <span
class="math inline">\((S&#39;_1,S&#39;_2)\in\mathcal{S}&#39;^\pm\)</span>
by <span class="math inline">\(S&#39;_1-S&#39;_2\)</span> and interpret
it as a formal difference accordingly.</p>
<p>As discussed in the outline, we spend the next sections defining more
structure on the sets before modding out the right equivalence relation
in section 6.</p>
<h2 id="set-inclusions-injective-maps">3. Set inclusions (injective
maps)</h2>
<p>We define maps that will play the role of inclusion maps after our
equivalence relation (i.e. allow us to consider some sets as subsets of
other sets - will be/stay injections and form nothing but commutative
diagrams when concatenated):</p>
<h3 id="classical-and-pure-quantum-as-mixed-quantum-states">3.1.
Classical and pure quantum as mixed quantum states</h3>
<p>The inclusions are</p>
<ol type="1">
<li><span
class="math inline">\(\mathcal{S}&#39;_\mathrm{class}\to\mathcal{S}&#39;_\mathrm{decoh},\)</span>
<span class="math inline">\((M,P)\to(E\times M,
(\delta_{(e,e&#39;)}\delta_{(m,m&#39;)}\sqrt{P_{e,m}})_{(e,m),e&#39;,m&#39;})\)</span>
(in words, treating a classical as a completely decohered state),</li>
<li><span
class="math inline">\(\mathcal{S}&#39;_\mathrm{quant}\to\mathcal{S}&#39;_\mathrm{decoh},\)</span>
<span class="math inline">\((M,\Psi)\to(\{0\},
(\sqrt{P_{e,m}})_{0,e,m})\)</span> (in words, treating a pure quantum
state as a quantum state with no decoherence).</li>
</ol>
<h3 id="knowledge-as-quasiknowledge">3.2. Knowledge as
quasiknowledge</h3>
<p><span
class="math inline">\(\mathcal{S}&#39;\to\mathcal{S}&#39;^\pm,\)</span>
<span class="math inline">\(S&#39;\to S&#39;-0\)</span>.</p>
<h3 id="elements-of-e">3.2. Elements of E</h3>
<p>We want to consider <span class="math inline">\(e\in E\)</span> as a
state in which the environment is guaranteed to be in state <span
class="math inline">\(e.\)</span></p>
<ol type="1">
<li><span
class="math inline">\(E\to\mathcal{S}&#39;_\mathrm{class}\)</span>,
<span
class="math inline">\(e\to(\{0\},(\delta_{e&#39;,e})_{(e&#39;,0)\in
E\times \{0\}}))\)</span></li>
</ol>
<p>(where <span class="math inline">\(\{0\}\)</span> is an arbitrary
1-element memory space). The situation is completely analogous in the
pure-quantum or mixed-quantum case (in the latter, with a 1-dimensional
decohering space).</p>
<h3 id="real-numbers">3.3. Real numbers</h3>
<p><span class="math inline">\(\mathbb{R}^+\to
\mathcal{S}&#39;_\mathrm{class}\)</span> maps <span
class="math inline">\(r\)</span> to an all-<span
class="math inline">\(r\)</span> matrix, again with trivial memory
space. <span class="math inline">\(\mathbb{R}^+\to
\mathcal{S}&#39;_\mathrm{quant},\)</span> <span
class="math inline">\(\mathcal{S}&#39;_\mathrm{decoh}\)</span> map to an
all-<span class="math inline">\(\sqrt{r}\)</span> matrix with trivial
memory (and decohering) space.</p>
<p>We embed real numbers <span
class="math inline">\(-r&#39;&lt;0\)</span> in <span
class="math inline">\(\mathcal{S}&#39;^\pm\)</span> as <span
class="math inline">\(0-r&#39;\)</span>, i.e. as the negation of the
embedding of <span class="math inline">\(r&#39;\)</span>.</p>
<h2 id="operations">4. Operations</h2>
<p>We now define some operations on the <span
class="math inline">\(\mathcal{S}&#39;\)</span> and <span
class="math inline">\(\mathcal{S}&#39;^\pm.\)</span></p>
<ol type="1">
<li><p><strong>Addition,</strong> <span
class="math inline">\(+,\)</span> is to be interpreted as the
environment+agent being in either of the situations that the summands
describe, and defined with <strong>direct sums</strong>:</p>
<ol type="1">
<li>In <span
class="math inline">\(\mathcal{S}&#39;_{\mathrm{class}},\)</span> <span
class="math inline">\((M_1,P_1)+(M_2,P_2):=(M_1\biguplus M_2,
P&#39;),\)</span> with <span class="math inline">\(M_1\biguplus
M_2\)</span> denoting the disjoint union of <span
class="math inline">\(M_1\)</span> and <span
class="math inline">\(M_2\)</span> and the elements of <span
class="math inline">\(P&#39;\)</span> composed of the elements of <span
class="math inline">\(P_1\)</span> and <span
class="math inline">\(P_2.\)</span></li>
<li>In <span
class="math inline">\(\mathcal{S}&#39;_{\mathrm{quant}},\)</span> the
definition is equivalent.</li>
<li>In <span
class="math inline">\(\mathcal{S}&#39;_{\mathrm{decoh}},\)</span> <span
class="math inline">\((D_1,M_1,\Psi_1) + (D_2,M_2,\Psi_2) := (D_1
\biguplus D_2, M_1 \biguplus M_2, \Psi&#39;),\)</span> with the entries
of <span class="math inline">\(\Psi&#39;\)</span> taken from <span
class="math inline">\(\Psi&#39;_1,\Psi&#39;_2\)</span> if <span
class="math inline">\(d\)</span> and <span
class="math inline">\(m\)</span> belong to the same summand and set to
<span class="math inline">\(0\)</span> otherwise.</li>
</ol>
<p>In the <span class="math inline">\(\mathcal{S}&#39;^\pm,\)</span>
<span class="math inline">\((A-B) + (C-D) := ((A+C) - (B+D))\)</span> as
expected.</p></li>
<li><p>We denote <strong>multiplication</strong> on the <span
class="math inline">\(\mathcal{S}&#39;\)</span> by concatenating the
factors and interpret it as the model having access to two pieces of
knowledge independently. That is:</p>
<ol type="1">
<li>In <span
class="math inline">\(\mathcal{S}&#39;_{\mathrm{class}},\)</span> <span
class="math inline">\((M_1,P_1)(M_2,P_2) := (M_1 \times M_2,
P&#39;)\)</span> with <span class="math inline">\(P&#39;_{e, (m_1, m_2)}
:= (P_1)_{e, m_1} (P_2)_{e, m_2},\)</span></li>
<li>equivalently in <span
class="math inline">\(\mathcal{S}&#39;_{\mathrm{quant}},\)</span></li>
<li>and in <span
class="math inline">\(\mathcal{S}&#39;_{\mathrm{decoh}},\)</span> <span
class="math inline">\((D_1,M_1,\Psi_1) (D_2,M_2,\Psi_2) := (D_1 \times
D_2, M_1 \times M_2, \Psi&#39;)\)</span> with <span
class="math inline">\(\Psi&#39;_{(d_1, d_2), e, (m_1, m_2)} :=
(\Psi_1)_{d_1, e, m_1}(\Psi_2)_{d_2, e, m_2}.\)</span></li>
</ol>
<p>In the <span class="math inline">\(\mathcal{S}&#39;^\pm,\)</span>
<span class="math inline">\((A-B)(C-D) := (AC+BD) -
(AD+BC).\)</span></p></li>
<li><p>Remember that when we consider different possible environments,
we denote our sets by <span
class="math inline">\(\mathcal{S}&#39;^E\)</span> and similar.
Considering a bipartite environment <span class="math inline">\(E\times
C,\)</span> we define a <strong>“partial trace”</strong> <span
class="math inline">\(\mathrm{tr}_C \colon \mathcal{S}&#39;^{E\times
C}\to \mathcal{S}&#39;^E.\)</span> This works by considering the <span
class="math inline">\(C\)</span> register, which previously was part of
the environment, as part of the memory: it maps <span
class="math inline">\(M\to M\times C,\)</span> copies the entries of
<span class="math inline">\(P\)</span> or <span
class="math inline">\(\Psi\)</span> and (in the decohering case) leaves
<span class="math inline">\(D\)</span> untouched. After modding out an
equivalence relation in section 6, this will look more like the partial
trace - after making some information accessible to the agent, the state
of knowledge becomes equivalent with respect to all transformations that
it can perform on that information.</p>
<p>Of course, on the <span
class="math inline">\(\mathcal{S}&#39;^\pm,\)</span> the <span
class="math inline">\(\mathrm{tr}_C (A-B):= \mathrm{tr}_C A -
\mathrm{tr}_C B.\)</span></p>
<p>The partial trace will be useful to discuss the interface between
agent and the environment, i.e. discuss the possibility that the agent
makes observations or performs actions that influence the next system
state.</p></li>
<li><p>We define a <strong>preorder</strong> <span
class="math inline">\(S_1 \leq S_2\)</span> to capture the notion that
the agent can trivially transform a state into another state, as
follows:</p>
<ol type="1">
<li>In <span
class="math inline">\(\mathcal{S}&#39;_{\mathrm{class}},\)</span> <span
class="math inline">\((M_1,P_2 T^T) \leq (M_2,P_2)\)</span> for all
transformation matrices on the memory <span class="math inline">\(T \in
{(\mathbb{R}^+)}^{M_1 \times M_2}\)</span> with <span
class="math inline">\(\Vert T\Vert_1\leq 1.\)</span> <span
class="math inline">\(P_2 T^T\)</span> is the usual matrix product of
<span class="math inline">\(P_2\)</span> with the transpose of <span
class="math inline">\(T.\)</span> One can check that this corresponds to
applying <span class="math inline">\(T\)</span> on the <span
class="math inline">\(M\)</span> subsystem; this is an awkward
technicality related to us not using graphical notation. The latter is
the <a
href="https://en.wikipedia.org/w/index.php?title=Matrix_norm&amp;oldid=1100495446#Matrix_norms_induced_by_vector_p-norms">1-norm
of the transpose of <span class="math inline">\(T,\)</span> i.e. the
maximal row sum.</a> This means that starting from any state <span
class="math inline">\(m_2\in M_2,\)</span> the probabilities of
transitioning to a final state must sum to <strong>at most</strong> one;
if it is <span class="math inline">\(&lt;1\)</span> for some column, we
interpret this as the agent giving up with a certain probability. If
<em>all</em> column sums were <span class="math inline">\(1,\)</span>
we’d get a “proper” transition matrix that doesn’t lose probability
mass.</li>
<li>The definition in <span
class="math inline">\(\mathcal{S}&#39;_{\mathrm{quant}}\)</span> is
analogous (with <span class="math inline">\(\mathbb{R}^+\)</span>
replaced by <span class="math inline">\(\mathbb{C}\)</span>) except that
our constraint on <span class="math inline">\(T\)</span> is that <span
class="math inline">\(\Vert T\Vert_2\leq 1,\)</span> using the <a
href="https://en.wikipedia.org/w/index.php?title=Matrix_norm&amp;oldid=1100495446#Matrix_norms_induced_by_vector_p-norms">2-norm
of <span class="math inline">\(T\)</span></a>. This means that the
maximal singular value of <span class="math inline">\(T\)</span> is
<span class="math inline">\(\leq 1.\)</span> Analogously to 1.,
<em>all</em> singular values being <span
class="math inline">\(1\)</span> is equivalent to <span
class="math inline">\(T\)</span> being an isometry, i.e. a “proper”
quantum transition matrix. If some singular values of <span
class="math inline">\(T\)</span> are <span
class="math inline">\(&lt;1,\)</span> the block-matrix <span
class="math inline">\(\begin{pmatrix}T\\\\ \sqrt{I-T^\dagger
T}\end{pmatrix}\)</span> is an isometry nevertheless; we can imagine the
agent gives up if it lands in the lower block of that matrix and/or
consider <span class="math inline">\(T\)</span> to be one <a
href="https://en.wikipedia.org/w/index.php?title=Quantum_operation&amp;oldid=1094787035#Statement_of_the_theorem">Kraus
operator of a quantum channel</a>.</li>
<li>In <span
class="math inline">\(\mathcal{S}&#39;_{\mathrm{decoh}},\)</span> we
want to consider transitions involving both <span
class="math inline">\(D\)</span> and the memory. So we have <span
class="math inline">\((D_1,M_1, T_D(\Psi_2 T^T_M)) \leq (D_2, M_2,
\Psi_2),\)</span> where <span class="math inline">\(T_D(\Psi_2
T_M^T))\)</span> denotes
<ol type="1">
<li>The application of some <span class="math inline">\(T_M \in
\mathbb{C}^{M_2 \times (M_1 \times D_M)}\)</span> to the memory space of
<span class="math inline">\(\Psi_2,\)</span> where <span
class="math inline">\(D_M\)</span> is an intermediate decohering space
and <span class="math inline">\(\Vert T_M\Vert_2\leq 1,\)</span></li>
<li>following that, the application of <span
class="math inline">\(T_D\in \mathbb{C}^{D_1\times (D\times
D_M)}\)</span> to <span class="math inline">\(D\)</span> and <span
class="math inline">\(D_M\)</span>, with <span
class="math inline">\(\Vert T_D\Vert_2\leq 1\)</span> as well. So <span
class="math inline">\(T_M\)</span> transforms the memory and generates a
register <span class="math inline">\(D_M\)</span> that becomes part of
the decohering space, and <span class="math inline">\(T_D\)</span> is an
arbitrary transformation of that decohering space, which is <strong>not
necessarily an isometry either</strong>.<a href="#fn3"
class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a></li>
</ol></li>
</ol>
<p>On <span class="math inline">\(\mathbb{S}&#39;^\pm,\)</span> <span
class="math inline">\((A-B)\leq (C-D)\)</span> iff <span
class="math inline">\(A+D\leq B+D.\)</span></p></li>
</ol>
<h2 id="the-equivalence-relation-and-the-algebra">5. The equivalence
relation and the algebra</h2>
<p>Finally, we define an <strong>equivalence relation</strong> on the
<span class="math inline">\(\mathcal{S}&#39;\)</span> and <span
class="math inline">\(\mathcal{S}&#39;^\pm\)</span> by <span
class="math inline">\(X\sim Y\leftrightarrow (X\leq Y \wedge Y\leq
X)\)</span>, and call the equivalence classes the spaces of
<strong>states of knowledge</strong> <span
class="math inline">\(\mathcal{S}\)</span> and <strong>states of
quasiknowledge</strong> <span
class="math inline">\(\mathcal{S}^\pm\)</span>.<a href="#fn4"
class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<p>It is tedious but straightforward to check (fingers crossed) that all
our operations behave well with this equivalence relation and <span
class="math inline">\(\mathcal{S}\subseteq\mathcal{S}^\pm\)</span>
becomes a <strong>convex subset of an associative, commutative ordered
<span class="math inline">\(\mathbb{R}\)</span>-algebra</strong>.<a
href="#fn5" class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a></p>
<p>The partial trace <span
class="math inline">\(\mathrm{tr}_C\colon\mathcal{S}^{\pm (E\times
C)}\to \mathcal{S}^{\pm E}\)</span> is a <strong>linear map</strong>
that surjectively maps states of knowledge to states of knowledge
(i.e. the image <span
class="math inline">\(\mathrm{tr}_C(\mathcal{S}^{E\times
C})=\mathcal{S}^{E}\)</span>). Conversely, however, the preimage of a
SOK is <em>not</em> necessarily a SOK. <span
class="math inline">\(\mathrm{tr}_C\)</span> is also monotonous in <span
class="math inline">\(\leq\)</span>.</p>
<p>Note that after the equivalence relation, the set inclusion <span
class="math inline">\(\mathbb{R}\subseteq
\mathcal{S}^{\pm\{0\}}\)</span> defined in 3.3. is actually
<em>surjective</em> for a 1-element <span
class="math inline">\(E=\{0\}\)</span>. So it makes sense to define a
“total trace” <span class="math inline">\(\mathrm{tr}\colon
\mathcal{S}^{\pm}\to\mathbb{R}\)</span>, which treats the environment
<span class="math inline">\(E\)</span> as <span
class="math inline">\(\{0\}\times E\)</span> and calculates the partial
trace over <span class="math inline">\(E\)</span>. Interpreting the
result as an element of <span class="math inline">\(\mathbb{R},\)</span>
this returns the <span class="math inline">\(1\)</span>-norm/squared
<span class="math inline">\(2\)</span>-norm of a SOK.</p>
<h2 id="an-example-determining-the-bias-of-a-coin">6. An example:
determining the bias of a coin</h2>
<p>God has chosen a biased (classical) coin which either shows head with
<span class="math inline">\(p=0.6\)</span> or tails with <span
class="math inline">\(p=0.6\)</span>, the prior probabilities for each
are equal. The “agent” (in this simple example) can’t make any decisions
to influence the environment, it only observes the sequence of coin
flips.</p>
<p>In this situation, the environment is a 2-element set <span
class="math inline">\(E=\{\mathrm{HeadsBiased},\mathrm{TailsBiased}\}\)</span>;
denote this by <span class="math inline">\(E=\{0,1\}\)</span> for
simplicity. One representative for the initial state of knowledge <span
class="math inline">\(S_0\)</span> is <span
class="math inline">\((M,P)\)</span> with <span
class="math inline">\(M=\{0\}\)</span> and <span
class="math inline">\(P=\begin{pmatrix}1/2
\\1/2\end{pmatrix}=\frac{1}{2}\mathbf{1}.\)</span> This corresponds to
the agent having a trivial internal memory.</p>
<p>The agent could perform some internal memory transformations. For
example, it could introduce a new 3-state memory state <span
class="math inline">\(M&#39;=\{0,1,2\},\)</span> and randomly choose
<span class="math inline">\(0\)</span> with probability <span
class="math inline">\(1/2\)</span>, and <span
class="math inline">\(1\)</span> or <span
class="math inline">\(2\)</span> with probability <span
class="math inline">\(1/4\)</span> each. Then we’d get a representative
<span class="math inline">\((M&#39;, P&#39;)\)</span> with <span
class="math inline">\(P&#39;:=\begin{pmatrix} \frac{1}{4} &amp;
\frac{1}{8} &amp; \frac{1}{8} \\ \frac{1}{4} &amp; \frac{1}{8} &amp;
\frac{1}{8} \end{pmatrix}.\)</span> By our definitions, these
representatives are equivalent as states of knowledge:</p>
<p>$P’:=P T^T $ with <span class="math inline">\(T:=\begin{pmatrix}
\frac{1}{2} \\ \frac{1}{4} \\ \frac{1}{4} \end{pmatrix},\)</span></p>
<p>$P:= P’T’^T $ with <span
class="math inline">\(T&#39;:=\begin{pmatrix} 1 &amp; 1 &amp;
1\end{pmatrix},\)</span></p>
<p>and both <span class="math inline">\(T\)</span> and <span
class="math inline">\(T&#39;\)</span> have <span
class="math inline">\(1\)</span>-norm (maximal column sums) <span
class="math inline">\(\leq 1.\)</span> The latter transformation matrix
corresponds to forgetting <span class="math inline">\(M&#39;\)</span>
and getting back to a trivial memory state. So as we hoped, we have
modded out equivalent transformations that the agent could perform on
its internal memory.</p>
<p>The situation becomes more interesting after the agent made a few
observations of coin tosses. Suppose it makes a single observation and
stores the result as a memory state in <span
class="math inline">\(M:=\{h,t\}.\)</span> Then the joint probability
matrix becomes</p>
<p><span class="math inline">\(P:=\begin{pmatrix} \frac{0.6}{2} &amp;
\frac{0.4}{2} \\ \frac{0.4}{2} &amp;\frac{0.6}{2}
\end{pmatrix},\)</span></p>
<p>and a representative of our state of knowledge is <span
class="math inline">\((M,P).\)</span></p>
<p>After it made <span class="math inline">\(2\)</span> observations
(and stored both results), a representative is</p>
<p><span class="math inline">\((M_2,P_2)\)</span> with <span
class="math inline">\(M_2:=\{hh,ht,th,tt\}\)</span> and <span
class="math inline">\(P_2:=\begin{pmatrix} \frac{0.6*0.6}{2} &amp;
\frac{0.6*0.4}{2} &amp; \frac{0.4*0.6}{2} &amp;\frac{0.4*0.4}{2}\\
\frac{0.4*0.4}{2} &amp; \frac{0.4*0.6}{2} &amp; \frac{0.6*0.4}{2}
&amp;\frac{0.6*0.6}{2} \end{pmatrix}\)</span> - the internal memory can
store all combinations of outcomes, and standard probability theory
yields the joint probabilities.</p>
<p>We know that it is superfluous to store all outcomes: It suffices to
keep track of <em>how many times</em> the coin showed heads, as the
order doesn’t give additional information about which coin was chosen.
We will now see that the formalism reflects this, as a representative
for the latter form of storage is equivalent as a state of knowledge.
Choose</p>
<p><span class="math inline">\(M_2&#39;:=\{0,1,2\},\)</span></p>
<p><span class="math inline">\(T_2:=\begin{pmatrix} 1 &amp; 0 &amp; 0
&amp; 0\\ 0 &amp; 1 &amp; 1 &amp; 0\\ 0 &amp; 0 &amp; 0 &amp; 1
\end{pmatrix},\)</span></p>
<p><span class="math inline">\(T&#39;_2:=\begin{pmatrix} 1 &amp; 0 &amp;
0\\ 0 &amp; 0.5 &amp; 0 \\ 0 &amp; 0.5 &amp; 0\\ 0 &amp; 0 &amp;
1\end{pmatrix},\)</span></p>
<p><span class="math inline">\(P_2&#39;:=\begin{pmatrix} 0.18 &amp; 0.24
&amp; 0.08\\ 0.08 &amp; 0.24 &amp; 0.18 \end{pmatrix}.\)</span></p>
<p>Then <span class="math inline">\((M_2&#39;,P_2&#39;)\)</span>
represents the joint probabilities over environmental and memory states
when the agent only stores such a counter - and the matrices <span
class="math inline">\(T_2,\)</span> <span
class="math inline">\(T&#39;_2\)</span> are appropriate transformation
matrices (with column sums <span class="math inline">\(\leq 1\)</span>)
that prove that these representatives are equivalent in the space of
states of knowledge <span class="math inline">\(\mathcal{S}\)</span>.
The entries of <span class="math inline">\(P_2&#39;\)</span> are then
the appropriate joint probabilities of the coin being heads/tails-biased
and observing <span class="math inline">\(k\)</span> heads out of <span
class="math inline">\(2\)</span>, given by the binomial
distribution.</p>
<p>Given the representative <span
class="math inline">\((M&#39;_2,P&#39;_2)\)</span>, the agent can apply
<span class="math inline">\(T_2&#39;\)</span> to recreate a situation
equivalent to the original one (in which it stored the outcomes of all
individual coin flips).</p>
<p>In general, given a SOK <span
class="math inline">\(S\in\mathcal{S}\)</span>, observing an additional
coin flip and storing the result corresponds to multiplying <span
class="math inline">\(S\)</span> by a SOK <span
class="math inline">\(Q\)</span> represented by <span
class="math inline">\((M_Q,P_Q):=\left(\{e,h\},\begin{pmatrix}0.6 &amp;
0.4\\ 0.4 &amp; 0.6\end{pmatrix}\right)\)</span> according to our
formalism. In other words, if <span class="math inline">\(S\)</span> is
represented by <span class="math inline">\((M,P),\)</span> it gets
mapped to the equivalence class of <span class="math inline">\((M\times
M_Q, P&#39;)\)</span> with <span
class="math inline">\(P&#39;_{e,(m,x)}:= P_{e,m}(P_Q)_{e,x}.\)</span> So
after <span class="math inline">\(n\)</span> coin flips, the state of
knowledge is</p>
<p><span class="math inline">\(S=Q^n S_0.\)</span></p>
<p>Finally, suppose that in each step, the agent only observes a coin
flip with probability <span class="math inline">\(1/4,\)</span> and
doesn’t change its state of knowledge otherwise. So it gets one of the
outcomes <span class="math inline">\(M_p:=\{h,t,n\},\)</span> with a
conditional probability matrix</p>
<p><span class="math inline">\(\begin{pmatrix}0.15 &amp; 0.10 &amp;
0.75\\0.10 &amp; 0.15 &amp;
0.75\end{pmatrix}=\frac{1}{4}\begin{pmatrix}0.6 &amp; 0.4\\0.4 &amp;
0.6\end{pmatrix}\oplus\frac{3}{4}\begin{pmatrix}1\\1
\end{pmatrix}=\frac{1}{4}Q+\frac{3}{4}\mathbf{1}.\)</span></p>
<p>Here, the <span class="math inline">\(\oplus\)</span> signs stand for
concatenating the columns, just like in our definition of addition. Then
the state of knowledge after <span class="math inline">\(n\)</span>
events (that are coin flips with probability <span
class="math inline">\(1/4\)</span>) is</p>
<p><span class="math inline">\((\frac{1}{4}Q+\frac{3}{4}\mathbf{1})^n
S_0.\)</span></p>
<p>Similarly as in the situation above, one can show that it’s
sufficient for the agent to store a counter of heads and tails observed
so far.</p>
<h2 id="an-agent-interacting-with-its-environmentconvex-optimization">7.
An agent interacting with its environment/convex optimization</h2>
<h3 id="evolution">7.1. Evolution</h3>
<p>Now consider an agent interacting with its environment. So we
introduce some output and input subsystems <span
class="math inline">\(O,\)</span> <span
class="math inline">\(I,\)</span> and a “law of nature” <span
class="math inline">\(T\colon\mathcal{S}^{E\times O}\to
\mathcal{S}^{E\times I}\)</span> that evolves the environment influenced
by the agent’s choices, and generating measurement data. The “law of
nature” should be instantiated as some transition matrix <span
class="math inline">\(T&#39;\)</span>, similar to the ones in our order
definition in 4.4.:</p>
<ol type="1">
<li>For <span class="math inline">\(\mathcal{S}_\mathrm{class},\)</span>
<span class="math inline">\(T&#39;\in(\mathbb{R}^+)^{(E\times
I)\times(E\times O)}\)</span> and <span class="math inline">\(\Vert
T&#39;\Vert_1\leq 1,\)</span></li>
<li>For <span class="math inline">\(\mathcal{S}_\mathrm{quant},\)</span>
<span class="math inline">\(T&#39;\in\mathbb{C}^{(E\times
I)\times(E\times O)}\)</span> and <span class="math inline">\(\Vert
T&#39;\Vert_2\leq 1,\)</span></li>
<li>For <span class="math inline">\(\mathcal{S}_\mathrm{decoh},\)</span>
<span class="math inline">\(T&#39;\in\mathbb{C}^{(D_T\times E\times
I)\times(E\times O)}\)</span> and <span class="math inline">\(\Vert
T&#39;\Vert_2\leq 1,\)</span> i.e. <span
class="math inline">\(T&#39;\)</span> may add some new space <span
class="math inline">\(D_T\)</span> to the decohering space.</li>
</ol>
<p>Starting with a SOK <span class="math inline">\(S\in
\mathcal{S}^{E},\)</span> the states of knowledge attainable by the
agent in one step are then</p>
<p><span class="math inline">\(\left\{ \mathrm{tr}_I (T(S_O))
\mid\mathrm{tr}_O S_O \leq S, S_O\in \mathcal{S}^{E\times O}
\right\}:\)</span></p>
<p>The agent is able to apply an arbitrary transformation to its
internal state to write something in <span
class="math inline">\(O,\)</span> which corresponds to creating an
arbitrary SOK <span class="math inline">\(S_O\)</span> whose partial
trace is at most <span class="math inline">\(S.\)</span> Then the
transformation corresponds to applying T, and reading of the input is
application of the partial trace.</p>
<h3 id="measurements">7.2. Measurements</h3>
<p>Now suppose that given <span
class="math inline">\(S\in\mathcal{S}^E,\)</span> the agent wants to
calculate a function <span class="math inline">\(f\colon E\to
C.\)</span> As before, it produces some <span
class="math inline">\(S_C\in \mathcal{S}^{E\times C}\)</span> with <span
class="math inline">\(\mathrm{tr}_C S_C \leq S\)</span>. Given this
<span class="math inline">\(S_C,\)</span> the “probability” (in scare
quotes because <span class="math inline">\(S\)</span> doesn’t need to be
normalized) of getting output <span class="math inline">\(C\)</span> for
input <span class="math inline">\(E\)</span> is <span
class="math inline">\(\mathrm{tr}((E,C) S_C)\)</span> (with <span
class="math inline">\((E,C)\)</span> interpreted as a member of <span
class="math inline">\(\mathcal{S}^{E\times C}\)</span> as in 3.2):
Multiplying by <span class="math inline">\((E,C)\)</span> turns all
elements to <span class="math inline">\(0\)</span> that don’t correspond
to that combination, and <span
class="math inline">\(\mathrm{tr}\)</span> calculates the remaining
probability.</p>
<p>We can easily turn this into some output condition, e.g. the
condition that a SOK needs to allow the agent to calculate a function
with a given maximal error probability. What’s more, these are
<strong>convex</strong> conditions because the SOKs are convex and
partial traces are linear. So when we <strong>truncate to a finite
basis, we should be able to use convex optimization and duality</strong>
<a href="#fn6" class="footnote-ref" id="fnref6"
role="doc-noteref"><sup>6</sup></a> to find optimal algorithms that
allow the agent to determine some value or perform some manipulation of
the environment. This is a generalization of <a
href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.113.1101&amp;rep=rep1&amp;type=pdf">Barnum-Saks-Szegedy</a>.</p>
<p>TODO: We can also generalize the adversary bound.</p>
<h2 id="formal-power-series-of-knowledge">8. Formal power series of
knowledge</h2>
<p>Together, addition and multiplication allows us to define formal
power series of knowledge (we leave mathematical rigour for a moment, as
we didn’t define infinite sums). For example, suppose our learner
observes the stars with a telescope without making any choices. In an
infinitesimal time <span class="math inline">\(\Delta t\to 0,\)</span>
it observes a supernova with probability <span class="math inline">\(r
\Delta t,\)</span> generating experimental data <span
class="math inline">\(A\in \mathcal{S}.\)</span> Otherwise, it observes
nothing. If <span class="math inline">\(S(t)\)</span> is the state of
knowledge over time, we obtain</p>
<p><span class="math inline">\(S(t+\Delta t)\to ((1-r \Delta
t)\mathbf{1}+r\Delta t A) S(t).\)</span></p>
<p>This is solved by</p>
<p><span class="math inline">\(S(t)=\exp((A-\mathbf{1})rt)
S(0),\)</span></p>
<p>which is to be interpreted as the appropriate formal infinite power
series. In fact, writing</p>
<p><span
class="math inline">\(K(t)=\exp(-rt)\exp(Art)S(0)=\sum^\infty_{k=0}
\frac{\exp(-rt) (rt)^k}{k!} A^k S(0)\)</span></p>
<p>shows that the amount of knowledge obtained follows a Poisson
distribution. Note that these equations contain minus signs, so our
Grothendieck construction was probably helpful.</p>
<p>TODO: Maybe we can also define such a formal power series when the
agent is allowed to make choices - when considering <em>sets of
attainable states of knowledge</em> instead of <em>individual states of
knowledge</em>.</p>
<h2 id="footnotes">Footnotes</h2>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>Our convention is that each row is a different
environmental state, and each column a different internal memory
state.<a href="#fnref1" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>We could have defined it by density operators as well,
but it seems to me that the formalism introduced later won’t easily work
that way anymore.<a href="#fnref2" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>I think one can obtain a more elegant description of
possible transformations by adapting the parallel developments by <a
href="https://arxiv.org/pdf/quant-ph/0611234.pdf">Gutoski and
Watrous</a> and <a
href="https://journals.aps.org/pra/abstract/10.1103/PhysRevA.80.022339">Chiribella,
D’Ariano, and Perinotti</a>. But I don’t see a use of that as of this
note.<a href="#fnref3" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>If one looks into the definitions, one can see that the
“states of quasiknowledge” construction is related to a <a
href="https://en.wikipedia.org/wiki/Grothendieck_group">Grothendieck
group construction</a>. I looked into Wikipedia to read that this has
his name from a specific case “which resulted in the development of <a
href="https://en.wikipedia.org/w/index.php?title=K-theory&amp;oldid=1072713370">K-theory</a>”.
What’s written there looks formally quite similar to what I do here,
though I don’t understand it in detail. So maybe one can call these
thoughts “K-theory on the space of probabilistic transformations?”<a
href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>A side remark: <span
class="math inline">\(\mathcal{S}_{\mathrm{quant}}\subset\mathcal{S}^\pm_{\mathrm{quant}}\)</span>
should be isomorphic to the algebra of complex positive semidefinite
<span class="math inline">\(E\times E\)</span> matrices (as a subset of
the Hermitian matrices), with elementwise addition and multiplication.
One can derive this by considering the <a
href="https://quantumcomputing.stackexchange.com/questions/9368/why-do-purifications-only-differ-by-a-local-unitary">unitary
equivalence of purifications of quantum states</a>.<a href="#fnref5"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>Apparently, <a
href="https://homepages.cwi.nl/~monique/ow-seminar-sdp/">this
Oberwolfach seminar</a> contains a lecture on infinite-dimensional
semidefinite optimization.<a href="#fnref6" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
